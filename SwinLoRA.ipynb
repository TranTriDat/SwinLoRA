{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f705c4a-3374-43fc-bcee-12feaa29287b",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "485b36d8-bc1b-4711-896f-3963739ed6a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Continue with regular imports\n",
    "import os\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "\n",
    "# Try to get torchinfo, install it if it doesn't work\n",
    "# try:\n",
    "from torchinfo import summary\n",
    "\n",
    "import transformers\n",
    "import peft\n",
    "\n",
    "import accelerate\n",
    "import evaluate\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "from torch.optim import AdamW\n",
    "from transformers import get_scheduler, ResNetForImageClassification\n",
    "\n",
    "from datasets import load_metric\n",
    "\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78570ae2-22c2-4ca9-8fc2-87a6c525355d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b563bd1c-8998-4582-b0bf-fcc8daca063c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db20f7a8-d925-4de3-af0b-7143e35ee010",
   "metadata": {},
   "source": [
    "# 2. Set up training testing dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "538e1d88-8d22-4dc8-8414-468f52d218cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dir = \"/lora/ISIC2019_train/ImageDR\"\n",
    "test_dir = \"/lora/ISIC2019_test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7b6b77f-631f-4742-8b88-7e80d308d15b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'path': 'lora/ISIC2019_train', 'labels': '/label', 'images': '/original_data', 'use_wandb': False, 'classes': ['AK', 'BCC', 'BKL', 'DF', 'MEL', 'NV', 'SCC', 'VASC'], 'format_file': '.jpg', 'arch': 'ViT', 'checkpoint': 'microsoft/resnet-50', 'dataset': 'ISIC-2019', 'epochs': 100, 'batch_size': 64, 'learning_rate': 0.001}\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "with open(\"config.yaml\", \"r\") as ymlfile:\n",
    "    cfg = yaml.safe_load(ymlfile)\n",
    "    print(cfg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4802849d-28bd-43f8-9cba-d297a79b6e1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import DatasetBuilder\n",
    "import datasets\n",
    "import yaml\n",
    "import os\n",
    "\n",
    "\n",
    "class ISICDataset(DatasetBuilder):\n",
    "    \n",
    "    VERSION = datasets.Version(\"1.0.0\")\n",
    "    \n",
    "    def _info(self):\n",
    "        return datasets.DatasetInfo(\n",
    "            description=\"ISIC-2019\",\n",
    "            features=datasets.Features({\n",
    "                'image': datasets.Value('string'),\n",
    "                'label': datasets.ClassLabel(names=[\"AK\", \"BCC\", \"BKL\", \"DF\", \"MEL\", \"NV\", \"SCC\", \"VASC\"]),\n",
    "            }),\n",
    "        )\n",
    "\n",
    "    def _split_generators(self, dl_manager):\n",
    "        # Point to the directory where your data resides\n",
    "        extracted_path = os.path.join(dl_manager.manual_dir, \"Image_DullRazor\")\n",
    "        return [\n",
    "            datasets.SplitGenerator(\n",
    "                name=datasets.Split.TRAIN,\n",
    "                gen_kwargs={\n",
    "                    \"filepath\": extracted_path,\n",
    "                    \"split\": \"train\",\n",
    "                },\n",
    "            ),\n",
    "        ]\n",
    "\n",
    "    def _generate_examples(self, filepath,split):\n",
    "        # You can adjust this method based on the exact structure of your data and how you want to read it\n",
    "        for label in [\"AK\", \"BCC\", \"BKL\", \"DF\", \"MEL\", \"NV\", \"SCC\", \"VASC\"]:\n",
    "            label_path = os.path.join(filepath, label)\n",
    "            for img_name in os.listdir(label_path):\n",
    "                yield f\"{label}_{img_name}\", {\n",
    "                    \"image\": os.path.join(label_path, img_name),\n",
    "                    \"label\": label,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1bac9f82-74c9-4b5d-97b2-93592d1a04d2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Resolving data files: 100%|████████████| 20264/20264 [00:00<00:00, 64355.48it/s]\n",
      "Found cached dataset imagefolder (/home/user/.cache/huggingface/datasets/imagefolder/ISIC-2019-60eb30a0cfbe6999/0.0.0/37fbb85cc714a338bea574ac6c7d0b5be5aff46c1862c1989b20e0771199e93f)\n"
     ]
    }
   ],
   "source": [
    "from datasets import DatasetBuilder\n",
    "import datasets\n",
    "\n",
    "dataset = datasets.load_dataset(\"imagefolder\",name=\"ISIC-2019\",data_dir=cfg['path']+cfg['images'], split='train')\n",
    "labels = dataset.features[\"label\"].names\n",
    "label2id, id2label = dict(), dict()\n",
    "for i, label in enumerate(labels):\n",
    "    label2id[label] = i\n",
    "    id2label[i] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6420bb16-6d33-4f5b-b0f7-d52b024de5e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'AK': 0,\n",
       "  'BCC': 1,\n",
       "  'BKL': 2,\n",
       "  'DF': 3,\n",
       "  'MEL': 4,\n",
       "  'NV': 5,\n",
       "  'SCC': 6,\n",
       "  'VASC': 7},\n",
       " {0: 'AK',\n",
       "  1: 'BCC',\n",
       "  2: 'BKL',\n",
       "  3: 'DF',\n",
       "  4: 'MEL',\n",
       "  5: 'NV',\n",
       "  6: 'SCC',\n",
       "  7: 'VASC'})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label2id, id2label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3bb78f7-1249-4d40-b1a4-eaebea2478ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# function\n",
    "\n",
    "def preprocess_train(example_batch):\n",
    "    \"\"\"Apply train_transforms across a batch.\"\"\"\n",
    "    example_batch[\"pixel_values\"] = [train_transforms(image.convert(\"RGB\")) for image in example_batch[\"image\"]]\n",
    "    return example_batch\n",
    "\n",
    "\n",
    "def preprocess_val(example_batch):\n",
    "    \"\"\"Apply val_transforms across a batch.\"\"\"\n",
    "    example_batch[\"pixel_values\"] = [val_transforms(image.convert(\"RGB\")) for image in example_batch[\"image\"]]\n",
    "    return example_batch\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    \"\"\"Computes accuracy on a batch of predictions\"\"\"\n",
    "    # predictions = np.argmax(eval_pred.predictions, axis=1)\n",
    "    # return metric.compute(predictions=predictions, references=eval_pred.label_ids)\n",
    "\n",
    "\n",
    "    pred = eval_pred\n",
    "    labels = pred.label_ids\n",
    "    # preds = pred.predictions.argmax(-1)\n",
    "    preds = np.argmax(eval_pred.predictions, axis=1)\n",
    "        \n",
    "    # Calculate \n",
    "    \n",
    "\n",
    "   # Calculate accuracy, precision, recall, and F1-score\n",
    "    accuracy = accuracy_score(labels, preds)\n",
    "    precision = precision_score(labels, preds, average='weighted', labels=np.unique(preds))\n",
    "    recall = recall_score(labels, preds, average='weighted')\n",
    "    f1 = f1_score(labels, preds, average='weighted')\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    }\n",
    "\n",
    "def collate_fn(examples):\n",
    "    pixel_values = torch.stack([example[\"pixel_values\"] for example in examples])\n",
    "    labels = torch.tensor([example[\"label\"] for example in examples])\n",
    "    return {\"pixel_values\": pixel_values, \"labels\": labels}\n",
    "\n",
    "def print_trainable_parameters(model):\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param:.2f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33fbc9f6-71da-46ba-807e-cc72831f9b34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomCallback(transformers.TrainerCallback):\n",
    "    def __init__(self, trainer) -> None:\n",
    "        super().__init__()\n",
    "        self._trainer = trainer\n",
    "        \n",
    "    def on_epoch_end(self, args, stage, control, **kwargs):\n",
    "        if control.should_evaluate:\n",
    "            control_copy = deepcopy(control)\n",
    "            self._trainer.evaluate(eval_dataset=self._trainer.train_dataset, metric_key_prefix=\"train\")\n",
    "            return control_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2acc4dd8-7a56-477c-b98d-c55d86070e45",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNextImageProcessor {\n",
       "  \"crop_pct\": 0.875,\n",
       "  \"do_normalize\": true,\n",
       "  \"do_rescale\": true,\n",
       "  \"do_resize\": true,\n",
       "  \"image_mean\": [\n",
       "    0.485,\n",
       "    0.456,\n",
       "    0.406\n",
       "  ],\n",
       "  \"image_processor_type\": \"ConvNextImageProcessor\",\n",
       "  \"image_std\": [\n",
       "    0.229,\n",
       "    0.224,\n",
       "    0.225\n",
       "  ],\n",
       "  \"resample\": 3,\n",
       "  \"rescale_factor\": 0.00392156862745098,\n",
       "  \"size\": {\n",
       "    \"shortest_edge\": 224\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_processor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5c68d9-e709-4762-97ed-4bf7e9a42554",
   "metadata": {},
   "source": [
    "## For ViT or SwinT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd2f657-beb2-4085-9fc9-358c0db92fe1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# img_processing = transformers.ViTImageProcessor(do_resize=True,\n",
    "#                                                do_normalize=True)\n",
    "image_processor = transformers.AutoImageProcessor.from_pretrained(cfg[\"checkpoint\"])\n",
    "normalize = torchvision.transforms.Normalize(mean=image_processor.image_mean, std=image_processor.image_std)\n",
    "train_transforms = torchvision.transforms.Compose(\n",
    "    [\n",
    "        torchvision.transforms.RandomResizedCrop(image_processor.size[\"height\"]),\n",
    "        torchvision.transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomAdjustSharpness(sharpness_factor=2, p=0.5),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]\n",
    ")\n",
    "val_transforms = torchvision.transforms.Compose(\n",
    "    [\n",
    "        torchvision.transforms.Resize(image_processor.size[\"height\"]),\n",
    "        torchvision.transforms.CenterCrop(image_processor.size[\"height\"]),\n",
    "        transforms.RandomAdjustSharpness(sharpness_factor=2, p=0.5),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]\n",
    ")\n",
    "splits = dataset.train_test_split(test_size=0.1)\n",
    "train_ds = splits[\"train\"]\n",
    "val_ds = splits[\"test\"]\n",
    "train_ds.set_transform(preprocess_train)\n",
    "val_ds.set_transform(preprocess_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff9db68-b191-48a8-bdb1-06d5ac6f225b",
   "metadata": {},
   "source": [
    "## For ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba8c5871-2520-4636-ba5e-215f8faf7ae1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n"
     ]
    }
   ],
   "source": [
    "image_processor = transformers.AutoImageProcessor.from_pretrained(cfg[\"checkpoint\"])\n",
    "normalize = torchvision.transforms.Normalize(mean=image_processor.image_mean, std=image_processor.image_std)\n",
    "train_transforms = torchvision.transforms.Compose(\n",
    "    [\n",
    "        torchvision.transforms.RandomResizedCrop(image_processor.size[\"shortest_edge\"]),\n",
    "        torchvision.transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomAdjustSharpness(sharpness_factor=2, p=0.5),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]\n",
    ")\n",
    "val_transforms = torchvision.transforms.Compose(\n",
    "    [\n",
    "        torchvision.transforms.Resize(image_processor.size[\"shortest_edge\"]),\n",
    "        torchvision.transforms.CenterCrop(image_processor.size[\"shortest_edge\"]),\n",
    "        transforms.RandomAdjustSharpness(sharpness_factor=2, p=0.5),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]\n",
    ")\n",
    "splits = dataset.train_test_split(test_size=0.1)\n",
    "train_ds = splits[\"train\"]\n",
    "val_ds = splits[\"test\"]\n",
    "train_ds.set_transform(preprocess_train)\n",
    "val_ds.set_transform(preprocess_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8e1058cb-1d12-4a80-9600-fd7161eb90dc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ResNetForImageClassification were not initialized from the model checkpoint at microsoft/resnet-50 and are newly initialized because the shapes did not match:\n",
      "- classifier.1.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([8]) in the model instantiated\n",
      "- classifier.1.weight: found shape torch.Size([1000, 2048]) in the checkpoint and torch.Size([8, 2048]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 23524424 || all params: 23524424 || trainable%: 100.00\n"
     ]
    }
   ],
   "source": [
    "# lora alpha should be smaller than lorra rank\n",
    "\n",
    "model = transformers.AutoModelForImageClassification.from_pretrained(\n",
    "    cfg[\"checkpoint\"],\n",
    "    num_labels=len(labels),\n",
    "    label2id=label2id,\n",
    "    id2label=id2label,\n",
    "    ignore_mismatched_sizes=True,\n",
    ")\n",
    "# Overfitting when r = 10, lora alpha = 16\n",
    "# slow at 70% even increase to 200 epoch, r = [8,16], alpha = [8,8]\n",
    "# Slow at 75% r=16, alpha=16, and overfitting at ep 80\n",
    "# alpha should >= 2*r\n",
    "\n",
    "# config = peft.LoraConfig(\n",
    "#     # r=64,\n",
    "#     # lora_alpha=16,\n",
    "#     r=4,\n",
    "#     lora_alpha=32,\n",
    "#     target_modules=[\"query\", \"value\"],\n",
    "    \n",
    "#     lora_dropout=0.005,\n",
    "#     bias=\"none\",\n",
    "#     modules_to_save=[\"classifier\"],\n",
    "# )\n",
    "\n",
    "# Target modules\n",
    "# \"List of module names or regex expression of the module names to replace with LoRA.\"\n",
    "# \"For example, ['q', 'v'] or '.*decoder.*(SelfAttention|EncDecAttention).*(q|v)$'.\"\n",
    "# \"This can also be a wildcard 'all-linear' which matches all linear/Conv1D layers except the output layer.\"\n",
    "# \"If not specified, modules will be chosen according to the model architecture, If the architecture is \"\n",
    "# \"not known, an error will be raised -- in this case, you should specify the target modules manually.\"\n",
    "\n",
    "# lora_model = peft.get_peft_model(model, config)\n",
    "# print_trainable_parameters(lora_model)\n",
    "\n",
    "# model = peft.get_peft_model(model)\n",
    "print_trainable_parameters(model)\n",
    "\n",
    "model_name = cfg[\"checkpoint\"].split(\"/\")[-1]\n",
    "args = transformers.TrainingArguments(\n",
    "    f\"{model_name}-finetuned-lora-ISIC-2019\",\n",
    "    remove_unused_columns=False,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=cfg[\"learning_rate\"],\n",
    "    per_device_train_batch_size=cfg[\"batch_size\"],\n",
    "    gradient_accumulation_steps=4,\n",
    "    per_device_eval_batch_size=cfg[\"batch_size\"],\n",
    "    fp16=True,\n",
    "    num_train_epochs=cfg[\"epochs\"],\n",
    "    # num_train_epochs=4,\n",
    "    \n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    push_to_hub=True,\n",
    "    label_names=[\"labels\"],\n",
    "    optim=\"adamw_torch\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff83191c-1a19-4c49-b54f-760e23a03337",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lvwerra/test',\n",
       " 'jordyvl/ece',\n",
       " 'angelina-wang/directional_bias_amplification',\n",
       " 'cpllab/syntaxgym',\n",
       " 'lvwerra/bary_score',\n",
       " 'hack/test_metric',\n",
       " 'yzha/ctc_eval',\n",
       " 'codeparrot/apps_metric',\n",
       " 'mfumanelli/geometric_mean',\n",
       " 'daiyizheng/valid',\n",
       " 'erntkn/dice_coefficient',\n",
       " 'mgfrantz/roc_auc_macro',\n",
       " 'Vlasta/pr_auc',\n",
       " 'gorkaartola/metric_for_tp_fp_samples',\n",
       " 'idsedykh/metric',\n",
       " 'idsedykh/codebleu2',\n",
       " 'idsedykh/codebleu',\n",
       " 'idsedykh/megaglue',\n",
       " 'cakiki/ndcg',\n",
       " 'Vertaix/vendiscore',\n",
       " 'GMFTBY/dailydialogevaluate',\n",
       " 'GMFTBY/dailydialog_evaluate',\n",
       " 'jzm-mailchimp/joshs_second_test_metric',\n",
       " 'ola13/precision_at_k',\n",
       " 'yulong-me/yl_metric',\n",
       " 'abidlabs/mean_iou',\n",
       " 'abidlabs/mean_iou2',\n",
       " 'KevinSpaghetti/accuracyk',\n",
       " 'NimaBoscarino/weat',\n",
       " 'ronaldahmed/nwentfaithfulness',\n",
       " 'Viona/infolm',\n",
       " 'kyokote/my_metric2',\n",
       " 'kashif/mape',\n",
       " 'Ochiroo/rouge_mn',\n",
       " 'giulio98/code_eval_outputs',\n",
       " 'leslyarun/fbeta_score',\n",
       " 'giulio98/codebleu',\n",
       " 'anz2/iliauniiccocrevaluation',\n",
       " 'zbeloki/m2',\n",
       " 'xu1998hz/sescore',\n",
       " 'dvitel/codebleu',\n",
       " 'NCSOFT/harim_plus',\n",
       " 'JP-SystemsX/nDCG',\n",
       " 'sportlosos/sescore',\n",
       " 'Drunper/metrica_tesi',\n",
       " 'jpxkqx/peak_signal_to_noise_ratio',\n",
       " 'jpxkqx/signal_to_reconstruction_error',\n",
       " 'hpi-dhc/FairEval',\n",
       " 'lvwerra/accuracy_score',\n",
       " 'ybelkada/cocoevaluate',\n",
       " 'harshhpareek/bertscore',\n",
       " 'posicube/mean_reciprocal_rank',\n",
       " 'bstrai/classification_report',\n",
       " 'omidf/squad_precision_recall',\n",
       " 'Josh98/nl2bash_m',\n",
       " 'BucketHeadP65/confusion_matrix',\n",
       " 'BucketHeadP65/roc_curve',\n",
       " 'yonting/average_precision_score',\n",
       " 'transZ/test_parascore',\n",
       " 'transZ/sbert_cosine',\n",
       " 'hynky/sklearn_proxy',\n",
       " 'xu1998hz/sescore_english_mt',\n",
       " 'xu1998hz/sescore_german_mt',\n",
       " 'xu1998hz/sescore_english_coco',\n",
       " 'xu1998hz/sescore_english_webnlg',\n",
       " 'unnati/kendall_tau_distance',\n",
       " 'Viona/fuzzy_reordering',\n",
       " 'Viona/kendall_tau',\n",
       " 'lhy/hamming_loss',\n",
       " 'lhy/ranking_loss',\n",
       " 'Muennighoff/code_eval_octopack',\n",
       " 'yuyijiong/quad_match_score',\n",
       " 'Splend1dchan/cosine_similarity',\n",
       " 'AlhitawiMohammed22/CER_Hu-Evaluation-Metrics',\n",
       " 'Yeshwant123/mcc',\n",
       " 'transformersegmentation/segmentation_scores',\n",
       " 'sma2023/wil',\n",
       " 'chanelcolgate/average_precision',\n",
       " 'ckb/unigram',\n",
       " 'Felipehonorato/eer',\n",
       " 'manueldeprada/beer',\n",
       " 'shunzh/apps_metric',\n",
       " 'He-Xingwei/sari_metric',\n",
       " 'langdonholmes/cohen_weighted_kappa',\n",
       " 'fschlatt/ner_eval',\n",
       " 'hyperml/balanced_accuracy',\n",
       " 'brian920128/doc_retrieve_metrics',\n",
       " 'guydav/restrictedpython_code_eval',\n",
       " 'k4black/codebleu',\n",
       " 'Natooz/ece',\n",
       " 'ingyu/klue_mrc',\n",
       " 'Vipitis/shadermatch',\n",
       " 'unitxt/metric',\n",
       " 'gabeorlanski/bc_eval',\n",
       " 'jjkim0807/code_eval',\n",
       " 'vichyt/metric-codebleu',\n",
       " 'repllabs/mean_reciprocal_rank',\n",
       " 'repllabs/mean_average_precision',\n",
       " 'mtc/fragments',\n",
       " 'DarrenChensformer/eval_keyphrase',\n",
       " 'kedudzic/charmatch',\n",
       " 'Vallp/ter',\n",
       " 'DarrenChensformer/relation_extraction',\n",
       " 'Ikala-allen/relation_extraction',\n",
       " 'danieldux/hierarchical_softmax_loss',\n",
       " 'nlpln/tst',\n",
       " 'bdsaglam/jer',\n",
       " 'davebulaval/meaningbert',\n",
       " 'fnvls/bleu1234',\n",
       " 'fnvls/bleu_1234',\n",
       " 'nevikw39/specificity',\n",
       " 'yqsong/execution_accuracy',\n",
       " 'shalakasatheesh/squad_v2',\n",
       " 'arthurvqin/pr_auc',\n",
       " 'd-matrix/dmx_perplexity',\n",
       " 'akki2825/accents_unplugged_eval',\n",
       " 'juliakaczor/accents_unplugged_eval',\n",
       " 'chimene/accents_unplugged_eval',\n",
       " 'Vickyage/accents_unplugged_eval',\n",
       " 'Qui-nn/accents_unplugged_eval',\n",
       " 'TelEl/accents_unplugged_eval',\n",
       " 'livvie/accents_unplugged_eval',\n",
       " 'DaliaCaRo/accents_unplugged_eval',\n",
       " 'alvinasvk/accents_unplugged_eval',\n",
       " 'LottieW/accents_unplugged_eval',\n",
       " 'LuckiestOne/valid_efficiency_score',\n",
       " 'Fritz02/execution_accuracy',\n",
       " 'huanghuayu/multiclass_brier_score',\n",
       " 'jialinsong/apps_metric',\n",
       " 'DoctorSlimm/bangalore_score',\n",
       " 'agkphysics/ccc',\n",
       " 'DoctorSlimm/kaushiks_criteria',\n",
       " 'CZLC/rouge_raw',\n",
       " 'bascobasculino/mot-metrics',\n",
       " 'SEA-AI/mot-metrics',\n",
       " 'SEA-AI/det-metrics',\n",
       " 'saicharan2804/my_metric',\n",
       " 'red1bluelost/evaluate_genericify_cpp',\n",
       " 'maksymdolgikh/seqeval_with_fbeta',\n",
       " 'Bekhouche/NED',\n",
       " 'danieldux/isco_hierarchical_accuracy',\n",
       " 'ginic/phone_errors',\n",
       " 'haotongye-shopee/ppl',\n",
       " 'berkatil/map',\n",
       " 'DarrenChensformer/action_generation',\n",
       " 'buelfhood/fbeta_score',\n",
       " 'danasone/ru_errant',\n",
       " 'helena-balabin/youden_index',\n",
       " 'SEA-AI/PanopticQuality',\n",
       " 'SEA-AI/box-metrics',\n",
       " 'MathewShen/bleu',\n",
       " 'ncoop57/levenshtein_distance',\n",
       " 'kaleidophon/almost_stochastic_order',\n",
       " 'lvwerra/element_count',\n",
       " 'prb977/cooccurrence_count',\n",
       " 'NimaBoscarino/pseudo_perplexity',\n",
       " 'ybelkada/toxicity',\n",
       " 'ronaldahmed/ccl_win',\n",
       " 'cakiki/tokens_per_byte',\n",
       " 'lsy641/distinct',\n",
       " 'grepLeigh/perplexity',\n",
       " 'Charles95/element_count',\n",
       " 'Charles95/accuracy']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate.list_evaluation_modules()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df5f58eb-78e1-4549-95ef-ee10876786f6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNetForImageClassification(\n",
       "  (resnet): ResNetModel(\n",
       "    (embedder): ResNetEmbeddings(\n",
       "      (embedder): ResNetConvLayer(\n",
       "        (convolution): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "        (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activation): ReLU()\n",
       "      )\n",
       "      (pooler): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (encoder): ResNetEncoder(\n",
       "      (stages): ModuleList(\n",
       "        (0): ResNetStage(\n",
       "          (layers): Sequential(\n",
       "            (0): ResNetBottleNeckLayer(\n",
       "              (shortcut): ResNetShortCut(\n",
       "                (convolution): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "              (layer): Sequential(\n",
       "                (0): ResNetConvLayer(\n",
       "                  (convolution): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (activation): ReLU()\n",
       "                )\n",
       "                (1): ResNetConvLayer(\n",
       "                  (convolution): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (activation): ReLU()\n",
       "                )\n",
       "                (2): ResNetConvLayer(\n",
       "                  (convolution): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (activation): Identity()\n",
       "                )\n",
       "              )\n",
       "              (activation): ReLU()\n",
       "            )\n",
       "            (1): ResNetBottleNeckLayer(\n",
       "              (shortcut): Identity()\n",
       "              (layer): Sequential(\n",
       "                (0): ResNetConvLayer(\n",
       "                  (convolution): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (activation): ReLU()\n",
       "                )\n",
       "                (1): ResNetConvLayer(\n",
       "                  (convolution): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (activation): ReLU()\n",
       "                )\n",
       "                (2): ResNetConvLayer(\n",
       "                  (convolution): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (activation): Identity()\n",
       "                )\n",
       "              )\n",
       "              (activation): ReLU()\n",
       "            )\n",
       "            (2): ResNetBottleNeckLayer(\n",
       "              (shortcut): Identity()\n",
       "              (layer): Sequential(\n",
       "                (0): ResNetConvLayer(\n",
       "                  (convolution): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (activation): ReLU()\n",
       "                )\n",
       "                (1): ResNetConvLayer(\n",
       "                  (convolution): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (activation): ReLU()\n",
       "                )\n",
       "                (2): ResNetConvLayer(\n",
       "                  (convolution): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (activation): Identity()\n",
       "                )\n",
       "              )\n",
       "              (activation): ReLU()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): ResNetStage(\n",
       "          (layers): Sequential(\n",
       "            (0): ResNetBottleNeckLayer(\n",
       "              (shortcut): ResNetShortCut(\n",
       "                (convolution): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "                (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "              (layer): Sequential(\n",
       "                (0): ResNetConvLayer(\n",
       "                  (convolution): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (activation): ReLU()\n",
       "                )\n",
       "                (1): ResNetConvLayer(\n",
       "                  (convolution): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "                  (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (activation): ReLU()\n",
       "                )\n",
       "                (2): ResNetConvLayer(\n",
       "                  (convolution): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (activation): Identity()\n",
       "                )\n",
       "              )\n",
       "              (activation): ReLU()\n",
       "            )\n",
       "            (1): ResNetBottleNeckLayer(\n",
       "              (shortcut): Identity()\n",
       "              (layer): Sequential(\n",
       "                (0): ResNetConvLayer(\n",
       "                  (convolution): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (activation): ReLU()\n",
       "                )\n",
       "                (1): ResNetConvLayer(\n",
       "                  (convolution): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (activation): ReLU()\n",
       "                )\n",
       "                (2): ResNetConvLayer(\n",
       "                  (convolution): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (activation): Identity()\n",
       "                )\n",
       "              )\n",
       "              (activation): ReLU()\n",
       "            )\n",
       "            (2): ResNetBottleNeckLayer(\n",
       "              (shortcut): Identity()\n",
       "              (layer): Sequential(\n",
       "                (0): ResNetConvLayer(\n",
       "                  (convolution): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (activation): ReLU()\n",
       "                )\n",
       "                (1): ResNetConvLayer(\n",
       "                  (convolution): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (activation): ReLU()\n",
       "                )\n",
       "                (2): ResNetConvLayer(\n",
       "                  (convolution): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (activation): Identity()\n",
       "                )\n",
       "              )\n",
       "              (activation): ReLU()\n",
       "            )\n",
       "            (3): ResNetBottleNeckLayer(\n",
       "              (shortcut): Identity()\n",
       "              (layer): Sequential(\n",
       "                (0): ResNetConvLayer(\n",
       "                  (convolution): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (activation): ReLU()\n",
       "                )\n",
       "                (1): ResNetConvLayer(\n",
       "                  (convolution): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (activation): ReLU()\n",
       "                )\n",
       "                (2): ResNetConvLayer(\n",
       "                  (convolution): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (activation): Identity()\n",
       "                )\n",
       "              )\n",
       "              (activation): ReLU()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): ResNetStage(\n",
       "          (layers): Sequential(\n",
       "            (0): ResNetBottleNeckLayer(\n",
       "              (shortcut): ResNetShortCut(\n",
       "                (convolution): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "                (normalization): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "              (layer): Sequential(\n",
       "                (0): ResNetConvLayer(\n",
       "                  (convolution): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (activation): ReLU()\n",
       "                )\n",
       "                (1): ResNetConvLayer(\n",
       "                  (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (activation): ReLU()\n",
       "                )\n",
       "                (2): ResNetConvLayer(\n",
       "                  (convolution): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (normalization): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (activation): Identity()\n",
       "                )\n",
       "              )\n",
       "              (activation): ReLU()\n",
       "            )\n",
       "            (1): ResNetBottleNeckLayer(\n",
       "              (shortcut): Identity()\n",
       "              (layer): Sequential(\n",
       "                (0): ResNetConvLayer(\n",
       "                  (convolution): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (activation): ReLU()\n",
       "                )\n",
       "                (1): ResNetConvLayer(\n",
       "                  (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (activation): ReLU()\n",
       "                )\n",
       "                (2): ResNetConvLayer(\n",
       "                  (convolution): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (normalization): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (activation): Identity()\n",
       "                )\n",
       "              )\n",
       "              (activation): ReLU()\n",
       "            )\n",
       "            (2): ResNetBottleNeckLayer(\n",
       "              (shortcut): Identity()\n",
       "              (layer): Sequential(\n",
       "                (0): ResNetConvLayer(\n",
       "                  (convolution): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (activation): ReLU()\n",
       "                )\n",
       "                (1): ResNetConvLayer(\n",
       "                  (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (activation): ReLU()\n",
       "                )\n",
       "                (2): ResNetConvLayer(\n",
       "                  (convolution): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (normalization): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (activation): Identity()\n",
       "                )\n",
       "              )\n",
       "              (activation): ReLU()\n",
       "            )\n",
       "            (3): ResNetBottleNeckLayer(\n",
       "              (shortcut): Identity()\n",
       "              (layer): Sequential(\n",
       "                (0): ResNetConvLayer(\n",
       "                  (convolution): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (activation): ReLU()\n",
       "                )\n",
       "                (1): ResNetConvLayer(\n",
       "                  (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (activation): ReLU()\n",
       "                )\n",
       "                (2): ResNetConvLayer(\n",
       "                  (convolution): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (normalization): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (activation): Identity()\n",
       "                )\n",
       "              )\n",
       "              (activation): ReLU()\n",
       "            )\n",
       "            (4): ResNetBottleNeckLayer(\n",
       "              (shortcut): Identity()\n",
       "              (layer): Sequential(\n",
       "                (0): ResNetConvLayer(\n",
       "                  (convolution): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (activation): ReLU()\n",
       "                )\n",
       "                (1): ResNetConvLayer(\n",
       "                  (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (activation): ReLU()\n",
       "                )\n",
       "                (2): ResNetConvLayer(\n",
       "                  (convolution): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (normalization): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (activation): Identity()\n",
       "                )\n",
       "              )\n",
       "              (activation): ReLU()\n",
       "            )\n",
       "            (5): ResNetBottleNeckLayer(\n",
       "              (shortcut): Identity()\n",
       "              (layer): Sequential(\n",
       "                (0): ResNetConvLayer(\n",
       "                  (convolution): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (activation): ReLU()\n",
       "                )\n",
       "                (1): ResNetConvLayer(\n",
       "                  (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (activation): ReLU()\n",
       "                )\n",
       "                (2): ResNetConvLayer(\n",
       "                  (convolution): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (normalization): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (activation): Identity()\n",
       "                )\n",
       "              )\n",
       "              (activation): ReLU()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): ResNetStage(\n",
       "          (layers): Sequential(\n",
       "            (0): ResNetBottleNeckLayer(\n",
       "              (shortcut): ResNetShortCut(\n",
       "                (convolution): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "                (normalization): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "              (layer): Sequential(\n",
       "                (0): ResNetConvLayer(\n",
       "                  (convolution): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (activation): ReLU()\n",
       "                )\n",
       "                (1): ResNetConvLayer(\n",
       "                  (convolution): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "                  (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (activation): ReLU()\n",
       "                )\n",
       "                (2): ResNetConvLayer(\n",
       "                  (convolution): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (normalization): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (activation): Identity()\n",
       "                )\n",
       "              )\n",
       "              (activation): ReLU()\n",
       "            )\n",
       "            (1): ResNetBottleNeckLayer(\n",
       "              (shortcut): Identity()\n",
       "              (layer): Sequential(\n",
       "                (0): ResNetConvLayer(\n",
       "                  (convolution): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (activation): ReLU()\n",
       "                )\n",
       "                (1): ResNetConvLayer(\n",
       "                  (convolution): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (activation): ReLU()\n",
       "                )\n",
       "                (2): ResNetConvLayer(\n",
       "                  (convolution): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (normalization): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (activation): Identity()\n",
       "                )\n",
       "              )\n",
       "              (activation): ReLU()\n",
       "            )\n",
       "            (2): ResNetBottleNeckLayer(\n",
       "              (shortcut): Identity()\n",
       "              (layer): Sequential(\n",
       "                (0): ResNetConvLayer(\n",
       "                  (convolution): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (activation): ReLU()\n",
       "                )\n",
       "                (1): ResNetConvLayer(\n",
       "                  (convolution): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (activation): ReLU()\n",
       "                )\n",
       "                (2): ResNetConvLayer(\n",
       "                  (convolution): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (normalization): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (activation): Identity()\n",
       "                )\n",
       "              )\n",
       "              (activation): ReLU()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=2048, out_features=8, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lora_model\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5870bf24-07aa-467e-ab9b-1e5f2d01ec90",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtridat123123\u001b[0m (\u001b[33mtridat\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.6 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/user/Dat/Vit/wandb/run-20240507_224336-nf4fnho3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/tridat/huggingface/runs/nf4fnho3' target=\"_blank\">fine-sun-87</a></strong> to <a href='https://wandb.ai/tridat/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/tridat/huggingface' target=\"_blank\">https://wandb.ai/tridat/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/tridat/huggingface/runs/nf4fnho3' target=\"_blank\">https://wandb.ai/tridat/huggingface/runs/nf4fnho3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7100' max='7100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7100/7100 18:35:02, Epoch 99/100]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.962100</td>\n",
       "      <td>0.928395</td>\n",
       "      <td>0.665131</td>\n",
       "      <td>0.649198</td>\n",
       "      <td>0.665131</td>\n",
       "      <td>0.610812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.962100</td>\n",
       "      <td>0.926213</td>\n",
       "      <td>0.670449</td>\n",
       "      <td>0.661638</td>\n",
       "      <td>0.670449</td>\n",
       "      <td>0.614808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.812900</td>\n",
       "      <td>0.780976</td>\n",
       "      <td>0.720787</td>\n",
       "      <td>0.702114</td>\n",
       "      <td>0.720787</td>\n",
       "      <td>0.697629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.812900</td>\n",
       "      <td>0.763296</td>\n",
       "      <td>0.732116</td>\n",
       "      <td>0.709801</td>\n",
       "      <td>0.732116</td>\n",
       "      <td>0.712758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.767200</td>\n",
       "      <td>0.688448</td>\n",
       "      <td>0.754346</td>\n",
       "      <td>0.749873</td>\n",
       "      <td>0.754346</td>\n",
       "      <td>0.741229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.767200</td>\n",
       "      <td>0.709553</td>\n",
       "      <td>0.753823</td>\n",
       "      <td>0.743865</td>\n",
       "      <td>0.753823</td>\n",
       "      <td>0.740572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.708300</td>\n",
       "      <td>0.630396</td>\n",
       "      <td>0.767944</td>\n",
       "      <td>0.770407</td>\n",
       "      <td>0.767944</td>\n",
       "      <td>0.751971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.708300</td>\n",
       "      <td>0.681141</td>\n",
       "      <td>0.757277</td>\n",
       "      <td>0.763884</td>\n",
       "      <td>0.757277</td>\n",
       "      <td>0.745463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.634700</td>\n",
       "      <td>0.542056</td>\n",
       "      <td>0.809508</td>\n",
       "      <td>0.803214</td>\n",
       "      <td>0.809508</td>\n",
       "      <td>0.802295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.634700</td>\n",
       "      <td>0.621284</td>\n",
       "      <td>0.772570</td>\n",
       "      <td>0.759236</td>\n",
       "      <td>0.772570</td>\n",
       "      <td>0.762777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.571200</td>\n",
       "      <td>0.468882</td>\n",
       "      <td>0.832154</td>\n",
       "      <td>0.828469</td>\n",
       "      <td>0.832154</td>\n",
       "      <td>0.828456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.571200</td>\n",
       "      <td>0.573279</td>\n",
       "      <td>0.787370</td>\n",
       "      <td>0.783709</td>\n",
       "      <td>0.787370</td>\n",
       "      <td>0.783918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.544800</td>\n",
       "      <td>0.461287</td>\n",
       "      <td>0.832977</td>\n",
       "      <td>0.832353</td>\n",
       "      <td>0.832977</td>\n",
       "      <td>0.830036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.544800</td>\n",
       "      <td>0.582315</td>\n",
       "      <td>0.796744</td>\n",
       "      <td>0.798758</td>\n",
       "      <td>0.796744</td>\n",
       "      <td>0.794986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.530900</td>\n",
       "      <td>0.417683</td>\n",
       "      <td>0.851291</td>\n",
       "      <td>0.852204</td>\n",
       "      <td>0.851291</td>\n",
       "      <td>0.849295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.530900</td>\n",
       "      <td>0.573644</td>\n",
       "      <td>0.803651</td>\n",
       "      <td>0.806150</td>\n",
       "      <td>0.803651</td>\n",
       "      <td>0.801263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.465300</td>\n",
       "      <td>0.376371</td>\n",
       "      <td>0.865932</td>\n",
       "      <td>0.864918</td>\n",
       "      <td>0.865932</td>\n",
       "      <td>0.863841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.465300</td>\n",
       "      <td>0.570386</td>\n",
       "      <td>0.807597</td>\n",
       "      <td>0.811976</td>\n",
       "      <td>0.807597</td>\n",
       "      <td>0.807522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.423900</td>\n",
       "      <td>0.355165</td>\n",
       "      <td>0.870977</td>\n",
       "      <td>0.869452</td>\n",
       "      <td>0.870977</td>\n",
       "      <td>0.868710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.423900</td>\n",
       "      <td>0.579648</td>\n",
       "      <td>0.813024</td>\n",
       "      <td>0.808140</td>\n",
       "      <td>0.813024</td>\n",
       "      <td>0.808640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.388600</td>\n",
       "      <td>0.318823</td>\n",
       "      <td>0.887262</td>\n",
       "      <td>0.888586</td>\n",
       "      <td>0.887262</td>\n",
       "      <td>0.886870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.388600</td>\n",
       "      <td>0.535383</td>\n",
       "      <td>0.820918</td>\n",
       "      <td>0.824269</td>\n",
       "      <td>0.820918</td>\n",
       "      <td>0.819887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.384300</td>\n",
       "      <td>0.298292</td>\n",
       "      <td>0.893239</td>\n",
       "      <td>0.895226</td>\n",
       "      <td>0.893239</td>\n",
       "      <td>0.893501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.384300</td>\n",
       "      <td>0.542836</td>\n",
       "      <td>0.823878</td>\n",
       "      <td>0.831126</td>\n",
       "      <td>0.823878</td>\n",
       "      <td>0.825307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>0.258990</td>\n",
       "      <td>0.906509</td>\n",
       "      <td>0.906135</td>\n",
       "      <td>0.906509</td>\n",
       "      <td>0.905110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>0.513125</td>\n",
       "      <td>0.850025</td>\n",
       "      <td>0.848736</td>\n",
       "      <td>0.850025</td>\n",
       "      <td>0.846660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.329300</td>\n",
       "      <td>0.253583</td>\n",
       "      <td>0.911608</td>\n",
       "      <td>0.911122</td>\n",
       "      <td>0.911608</td>\n",
       "      <td>0.910810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.329300</td>\n",
       "      <td>0.537995</td>\n",
       "      <td>0.826344</td>\n",
       "      <td>0.824115</td>\n",
       "      <td>0.826344</td>\n",
       "      <td>0.823857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.295100</td>\n",
       "      <td>0.227617</td>\n",
       "      <td>0.921369</td>\n",
       "      <td>0.920864</td>\n",
       "      <td>0.921369</td>\n",
       "      <td>0.920737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.295100</td>\n",
       "      <td>0.539437</td>\n",
       "      <td>0.834731</td>\n",
       "      <td>0.831834</td>\n",
       "      <td>0.834731</td>\n",
       "      <td>0.832481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.255800</td>\n",
       "      <td>0.219770</td>\n",
       "      <td>0.921423</td>\n",
       "      <td>0.921363</td>\n",
       "      <td>0.921423</td>\n",
       "      <td>0.920305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.255800</td>\n",
       "      <td>0.516320</td>\n",
       "      <td>0.845091</td>\n",
       "      <td>0.842417</td>\n",
       "      <td>0.845091</td>\n",
       "      <td>0.841249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.268000</td>\n",
       "      <td>0.198569</td>\n",
       "      <td>0.929100</td>\n",
       "      <td>0.929244</td>\n",
       "      <td>0.929100</td>\n",
       "      <td>0.928485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.268000</td>\n",
       "      <td>0.543715</td>\n",
       "      <td>0.849531</td>\n",
       "      <td>0.847819</td>\n",
       "      <td>0.849531</td>\n",
       "      <td>0.845912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.239400</td>\n",
       "      <td>0.199588</td>\n",
       "      <td>0.930471</td>\n",
       "      <td>0.930247</td>\n",
       "      <td>0.930471</td>\n",
       "      <td>0.930202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.239400</td>\n",
       "      <td>0.563227</td>\n",
       "      <td>0.851011</td>\n",
       "      <td>0.848673</td>\n",
       "      <td>0.851011</td>\n",
       "      <td>0.849248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.215100</td>\n",
       "      <td>0.193322</td>\n",
       "      <td>0.931842</td>\n",
       "      <td>0.932102</td>\n",
       "      <td>0.931842</td>\n",
       "      <td>0.931004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.215100</td>\n",
       "      <td>0.555245</td>\n",
       "      <td>0.844105</td>\n",
       "      <td>0.842065</td>\n",
       "      <td>0.844105</td>\n",
       "      <td>0.841265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.233900</td>\n",
       "      <td>0.182846</td>\n",
       "      <td>0.936338</td>\n",
       "      <td>0.936000</td>\n",
       "      <td>0.936338</td>\n",
       "      <td>0.935966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.233900</td>\n",
       "      <td>0.561308</td>\n",
       "      <td>0.840158</td>\n",
       "      <td>0.836528</td>\n",
       "      <td>0.840158</td>\n",
       "      <td>0.837405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.227400</td>\n",
       "      <td>0.189554</td>\n",
       "      <td>0.932171</td>\n",
       "      <td>0.931846</td>\n",
       "      <td>0.932171</td>\n",
       "      <td>0.931579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.227400</td>\n",
       "      <td>0.572700</td>\n",
       "      <td>0.838185</td>\n",
       "      <td>0.834564</td>\n",
       "      <td>0.838185</td>\n",
       "      <td>0.835217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.194700</td>\n",
       "      <td>0.174790</td>\n",
       "      <td>0.939573</td>\n",
       "      <td>0.939972</td>\n",
       "      <td>0.939573</td>\n",
       "      <td>0.938975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.194700</td>\n",
       "      <td>0.567490</td>\n",
       "      <td>0.856931</td>\n",
       "      <td>0.857220</td>\n",
       "      <td>0.856931</td>\n",
       "      <td>0.853846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.207100</td>\n",
       "      <td>0.150457</td>\n",
       "      <td>0.948127</td>\n",
       "      <td>0.948373</td>\n",
       "      <td>0.948127</td>\n",
       "      <td>0.947628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.207100</td>\n",
       "      <td>0.557212</td>\n",
       "      <td>0.847558</td>\n",
       "      <td>0.844543</td>\n",
       "      <td>0.847558</td>\n",
       "      <td>0.844678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.210300</td>\n",
       "      <td>0.155528</td>\n",
       "      <td>0.946702</td>\n",
       "      <td>0.946815</td>\n",
       "      <td>0.946702</td>\n",
       "      <td>0.946449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.210300</td>\n",
       "      <td>0.556255</td>\n",
       "      <td>0.849038</td>\n",
       "      <td>0.848978</td>\n",
       "      <td>0.849038</td>\n",
       "      <td>0.848177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.171400</td>\n",
       "      <td>0.149475</td>\n",
       "      <td>0.948127</td>\n",
       "      <td>0.948154</td>\n",
       "      <td>0.948127</td>\n",
       "      <td>0.947919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.171400</td>\n",
       "      <td>0.540441</td>\n",
       "      <td>0.854465</td>\n",
       "      <td>0.854661</td>\n",
       "      <td>0.854465</td>\n",
       "      <td>0.853262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.190300</td>\n",
       "      <td>0.163181</td>\n",
       "      <td>0.942973</td>\n",
       "      <td>0.943765</td>\n",
       "      <td>0.942973</td>\n",
       "      <td>0.943126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.190300</td>\n",
       "      <td>0.565440</td>\n",
       "      <td>0.845585</td>\n",
       "      <td>0.851084</td>\n",
       "      <td>0.845585</td>\n",
       "      <td>0.846570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.176500</td>\n",
       "      <td>0.135736</td>\n",
       "      <td>0.952514</td>\n",
       "      <td>0.952644</td>\n",
       "      <td>0.952514</td>\n",
       "      <td>0.952515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.176500</td>\n",
       "      <td>0.553495</td>\n",
       "      <td>0.850025</td>\n",
       "      <td>0.851513</td>\n",
       "      <td>0.850025</td>\n",
       "      <td>0.850162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.164400</td>\n",
       "      <td>0.137443</td>\n",
       "      <td>0.951966</td>\n",
       "      <td>0.951925</td>\n",
       "      <td>0.951966</td>\n",
       "      <td>0.951765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.164400</td>\n",
       "      <td>0.566259</td>\n",
       "      <td>0.860385</td>\n",
       "      <td>0.862445</td>\n",
       "      <td>0.860385</td>\n",
       "      <td>0.860295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.161300</td>\n",
       "      <td>0.127665</td>\n",
       "      <td>0.954269</td>\n",
       "      <td>0.954157</td>\n",
       "      <td>0.954269</td>\n",
       "      <td>0.954123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.161300</td>\n",
       "      <td>0.577646</td>\n",
       "      <td>0.863345</td>\n",
       "      <td>0.862779</td>\n",
       "      <td>0.863345</td>\n",
       "      <td>0.862426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.170200</td>\n",
       "      <td>0.130819</td>\n",
       "      <td>0.954762</td>\n",
       "      <td>0.954877</td>\n",
       "      <td>0.954762</td>\n",
       "      <td>0.954528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.170200</td>\n",
       "      <td>0.561132</td>\n",
       "      <td>0.864332</td>\n",
       "      <td>0.864031</td>\n",
       "      <td>0.864332</td>\n",
       "      <td>0.861763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.152700</td>\n",
       "      <td>0.119978</td>\n",
       "      <td>0.959917</td>\n",
       "      <td>0.959957</td>\n",
       "      <td>0.959917</td>\n",
       "      <td>0.959757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.152700</td>\n",
       "      <td>0.582483</td>\n",
       "      <td>0.866305</td>\n",
       "      <td>0.863494</td>\n",
       "      <td>0.866305</td>\n",
       "      <td>0.863784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.156500</td>\n",
       "      <td>0.114388</td>\n",
       "      <td>0.960136</td>\n",
       "      <td>0.960196</td>\n",
       "      <td>0.960136</td>\n",
       "      <td>0.959870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.156500</td>\n",
       "      <td>0.570314</td>\n",
       "      <td>0.861371</td>\n",
       "      <td>0.858675</td>\n",
       "      <td>0.861371</td>\n",
       "      <td>0.858949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.160200</td>\n",
       "      <td>0.111726</td>\n",
       "      <td>0.961616</td>\n",
       "      <td>0.961607</td>\n",
       "      <td>0.961616</td>\n",
       "      <td>0.961412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.160200</td>\n",
       "      <td>0.564505</td>\n",
       "      <td>0.865812</td>\n",
       "      <td>0.865568</td>\n",
       "      <td>0.865812</td>\n",
       "      <td>0.864497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.161400</td>\n",
       "      <td>0.118858</td>\n",
       "      <td>0.957723</td>\n",
       "      <td>0.957849</td>\n",
       "      <td>0.957723</td>\n",
       "      <td>0.957735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.161400</td>\n",
       "      <td>0.576733</td>\n",
       "      <td>0.861865</td>\n",
       "      <td>0.860939</td>\n",
       "      <td>0.861865</td>\n",
       "      <td>0.860818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.156100</td>\n",
       "      <td>0.114275</td>\n",
       "      <td>0.961123</td>\n",
       "      <td>0.961123</td>\n",
       "      <td>0.961123</td>\n",
       "      <td>0.961068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.156100</td>\n",
       "      <td>0.575965</td>\n",
       "      <td>0.860385</td>\n",
       "      <td>0.858622</td>\n",
       "      <td>0.860385</td>\n",
       "      <td>0.858900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.150500</td>\n",
       "      <td>0.107679</td>\n",
       "      <td>0.963810</td>\n",
       "      <td>0.963724</td>\n",
       "      <td>0.963810</td>\n",
       "      <td>0.963706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.150500</td>\n",
       "      <td>0.564746</td>\n",
       "      <td>0.871732</td>\n",
       "      <td>0.870272</td>\n",
       "      <td>0.871732</td>\n",
       "      <td>0.870487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.133900</td>\n",
       "      <td>0.108927</td>\n",
       "      <td>0.962165</td>\n",
       "      <td>0.962301</td>\n",
       "      <td>0.962165</td>\n",
       "      <td>0.962028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.133900</td>\n",
       "      <td>0.585976</td>\n",
       "      <td>0.862852</td>\n",
       "      <td>0.862712</td>\n",
       "      <td>0.862852</td>\n",
       "      <td>0.861190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.130800</td>\n",
       "      <td>0.104221</td>\n",
       "      <td>0.963700</td>\n",
       "      <td>0.963788</td>\n",
       "      <td>0.963700</td>\n",
       "      <td>0.963529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.130800</td>\n",
       "      <td>0.590030</td>\n",
       "      <td>0.872225</td>\n",
       "      <td>0.872018</td>\n",
       "      <td>0.872225</td>\n",
       "      <td>0.869935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.135900</td>\n",
       "      <td>0.098822</td>\n",
       "      <td>0.965400</td>\n",
       "      <td>0.965349</td>\n",
       "      <td>0.965400</td>\n",
       "      <td>0.965289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.135900</td>\n",
       "      <td>0.532183</td>\n",
       "      <td>0.874198</td>\n",
       "      <td>0.872471</td>\n",
       "      <td>0.874198</td>\n",
       "      <td>0.872929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.129400</td>\n",
       "      <td>0.102308</td>\n",
       "      <td>0.965181</td>\n",
       "      <td>0.965130</td>\n",
       "      <td>0.965181</td>\n",
       "      <td>0.965059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.129400</td>\n",
       "      <td>0.611995</td>\n",
       "      <td>0.865812</td>\n",
       "      <td>0.862502</td>\n",
       "      <td>0.865812</td>\n",
       "      <td>0.862331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.145400</td>\n",
       "      <td>0.099302</td>\n",
       "      <td>0.965126</td>\n",
       "      <td>0.965152</td>\n",
       "      <td>0.965126</td>\n",
       "      <td>0.964981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.145400</td>\n",
       "      <td>0.656494</td>\n",
       "      <td>0.870252</td>\n",
       "      <td>0.869232</td>\n",
       "      <td>0.870252</td>\n",
       "      <td>0.867710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.132800</td>\n",
       "      <td>0.105023</td>\n",
       "      <td>0.963700</td>\n",
       "      <td>0.963729</td>\n",
       "      <td>0.963700</td>\n",
       "      <td>0.963653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.132800</td>\n",
       "      <td>0.566594</td>\n",
       "      <td>0.874692</td>\n",
       "      <td>0.875063</td>\n",
       "      <td>0.874692</td>\n",
       "      <td>0.874154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.112500</td>\n",
       "      <td>0.094408</td>\n",
       "      <td>0.968032</td>\n",
       "      <td>0.967987</td>\n",
       "      <td>0.968032</td>\n",
       "      <td>0.967931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.112500</td>\n",
       "      <td>0.630446</td>\n",
       "      <td>0.869265</td>\n",
       "      <td>0.867688</td>\n",
       "      <td>0.869265</td>\n",
       "      <td>0.867472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.109800</td>\n",
       "      <td>0.092578</td>\n",
       "      <td>0.968032</td>\n",
       "      <td>0.968007</td>\n",
       "      <td>0.968032</td>\n",
       "      <td>0.967905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.109800</td>\n",
       "      <td>0.578111</td>\n",
       "      <td>0.873705</td>\n",
       "      <td>0.872454</td>\n",
       "      <td>0.873705</td>\n",
       "      <td>0.870743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.104300</td>\n",
       "      <td>0.087749</td>\n",
       "      <td>0.968855</td>\n",
       "      <td>0.968869</td>\n",
       "      <td>0.968855</td>\n",
       "      <td>0.968771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.104300</td>\n",
       "      <td>0.609102</td>\n",
       "      <td>0.872225</td>\n",
       "      <td>0.870640</td>\n",
       "      <td>0.872225</td>\n",
       "      <td>0.870382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.119800</td>\n",
       "      <td>0.092520</td>\n",
       "      <td>0.966990</td>\n",
       "      <td>0.966971</td>\n",
       "      <td>0.966990</td>\n",
       "      <td>0.966925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.119800</td>\n",
       "      <td>0.595629</td>\n",
       "      <td>0.869758</td>\n",
       "      <td>0.868651</td>\n",
       "      <td>0.869758</td>\n",
       "      <td>0.868325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.106200</td>\n",
       "      <td>0.087334</td>\n",
       "      <td>0.969787</td>\n",
       "      <td>0.969816</td>\n",
       "      <td>0.969787</td>\n",
       "      <td>0.969688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.106200</td>\n",
       "      <td>0.604020</td>\n",
       "      <td>0.876665</td>\n",
       "      <td>0.875002</td>\n",
       "      <td>0.876665</td>\n",
       "      <td>0.874032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.105900</td>\n",
       "      <td>0.085078</td>\n",
       "      <td>0.971212</td>\n",
       "      <td>0.971254</td>\n",
       "      <td>0.971212</td>\n",
       "      <td>0.971153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.105900</td>\n",
       "      <td>0.607895</td>\n",
       "      <td>0.873212</td>\n",
       "      <td>0.871886</td>\n",
       "      <td>0.873212</td>\n",
       "      <td>0.870917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.128600</td>\n",
       "      <td>0.091005</td>\n",
       "      <td>0.969184</td>\n",
       "      <td>0.969170</td>\n",
       "      <td>0.969184</td>\n",
       "      <td>0.969037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.128600</td>\n",
       "      <td>0.543246</td>\n",
       "      <td>0.869758</td>\n",
       "      <td>0.868136</td>\n",
       "      <td>0.869758</td>\n",
       "      <td>0.867601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.092100</td>\n",
       "      <td>0.082380</td>\n",
       "      <td>0.971322</td>\n",
       "      <td>0.971389</td>\n",
       "      <td>0.971322</td>\n",
       "      <td>0.971248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.092100</td>\n",
       "      <td>0.634551</td>\n",
       "      <td>0.866798</td>\n",
       "      <td>0.865719</td>\n",
       "      <td>0.866798</td>\n",
       "      <td>0.863502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.123500</td>\n",
       "      <td>0.079715</td>\n",
       "      <td>0.973351</td>\n",
       "      <td>0.973279</td>\n",
       "      <td>0.973351</td>\n",
       "      <td>0.973278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.123500</td>\n",
       "      <td>0.562703</td>\n",
       "      <td>0.875185</td>\n",
       "      <td>0.873358</td>\n",
       "      <td>0.875185</td>\n",
       "      <td>0.873463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>0.102400</td>\n",
       "      <td>0.080929</td>\n",
       "      <td>0.971870</td>\n",
       "      <td>0.971887</td>\n",
       "      <td>0.971870</td>\n",
       "      <td>0.971830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>0.102400</td>\n",
       "      <td>0.595667</td>\n",
       "      <td>0.882092</td>\n",
       "      <td>0.882102</td>\n",
       "      <td>0.882092</td>\n",
       "      <td>0.881136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>0.113600</td>\n",
       "      <td>0.078228</td>\n",
       "      <td>0.973296</td>\n",
       "      <td>0.973355</td>\n",
       "      <td>0.973296</td>\n",
       "      <td>0.973178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>0.113600</td>\n",
       "      <td>0.613793</td>\n",
       "      <td>0.878638</td>\n",
       "      <td>0.876535</td>\n",
       "      <td>0.878638</td>\n",
       "      <td>0.875402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>0.097500</td>\n",
       "      <td>0.077101</td>\n",
       "      <td>0.973625</td>\n",
       "      <td>0.973612</td>\n",
       "      <td>0.973625</td>\n",
       "      <td>0.973599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>0.097500</td>\n",
       "      <td>0.582891</td>\n",
       "      <td>0.877652</td>\n",
       "      <td>0.877267</td>\n",
       "      <td>0.877652</td>\n",
       "      <td>0.876482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>0.089900</td>\n",
       "      <td>0.076724</td>\n",
       "      <td>0.972857</td>\n",
       "      <td>0.972825</td>\n",
       "      <td>0.972857</td>\n",
       "      <td>0.972795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>0.089900</td>\n",
       "      <td>0.599767</td>\n",
       "      <td>0.874198</td>\n",
       "      <td>0.872774</td>\n",
       "      <td>0.874198</td>\n",
       "      <td>0.872765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.087600</td>\n",
       "      <td>0.071384</td>\n",
       "      <td>0.976147</td>\n",
       "      <td>0.976129</td>\n",
       "      <td>0.976147</td>\n",
       "      <td>0.976121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.087600</td>\n",
       "      <td>0.572883</td>\n",
       "      <td>0.888012</td>\n",
       "      <td>0.887537</td>\n",
       "      <td>0.888012</td>\n",
       "      <td>0.887093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.107300</td>\n",
       "      <td>0.074510</td>\n",
       "      <td>0.975106</td>\n",
       "      <td>0.975090</td>\n",
       "      <td>0.975106</td>\n",
       "      <td>0.975047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.107300</td>\n",
       "      <td>0.588212</td>\n",
       "      <td>0.881105</td>\n",
       "      <td>0.880165</td>\n",
       "      <td>0.881105</td>\n",
       "      <td>0.880266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>0.093200</td>\n",
       "      <td>0.071315</td>\n",
       "      <td>0.974831</td>\n",
       "      <td>0.974836</td>\n",
       "      <td>0.974831</td>\n",
       "      <td>0.974791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>0.093200</td>\n",
       "      <td>0.589048</td>\n",
       "      <td>0.870745</td>\n",
       "      <td>0.869224</td>\n",
       "      <td>0.870745</td>\n",
       "      <td>0.869041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>0.094900</td>\n",
       "      <td>0.070802</td>\n",
       "      <td>0.975599</td>\n",
       "      <td>0.975585</td>\n",
       "      <td>0.975599</td>\n",
       "      <td>0.975530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>0.094900</td>\n",
       "      <td>0.570754</td>\n",
       "      <td>0.879132</td>\n",
       "      <td>0.877450</td>\n",
       "      <td>0.879132</td>\n",
       "      <td>0.876819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.093200</td>\n",
       "      <td>0.067893</td>\n",
       "      <td>0.976915</td>\n",
       "      <td>0.976959</td>\n",
       "      <td>0.976915</td>\n",
       "      <td>0.976837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.093200</td>\n",
       "      <td>0.571656</td>\n",
       "      <td>0.879132</td>\n",
       "      <td>0.878212</td>\n",
       "      <td>0.879132</td>\n",
       "      <td>0.876831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.096600</td>\n",
       "      <td>0.065420</td>\n",
       "      <td>0.976367</td>\n",
       "      <td>0.976358</td>\n",
       "      <td>0.976367</td>\n",
       "      <td>0.976330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.096600</td>\n",
       "      <td>0.538045</td>\n",
       "      <td>0.885545</td>\n",
       "      <td>0.885344</td>\n",
       "      <td>0.885545</td>\n",
       "      <td>0.884619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>0.086500</td>\n",
       "      <td>0.073303</td>\n",
       "      <td>0.974996</td>\n",
       "      <td>0.975036</td>\n",
       "      <td>0.974996</td>\n",
       "      <td>0.974984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>0.086500</td>\n",
       "      <td>0.542989</td>\n",
       "      <td>0.881598</td>\n",
       "      <td>0.880587</td>\n",
       "      <td>0.881598</td>\n",
       "      <td>0.880058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>0.086600</td>\n",
       "      <td>0.067700</td>\n",
       "      <td>0.976422</td>\n",
       "      <td>0.976406</td>\n",
       "      <td>0.976422</td>\n",
       "      <td>0.976379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>0.086600</td>\n",
       "      <td>0.555463</td>\n",
       "      <td>0.885545</td>\n",
       "      <td>0.885225</td>\n",
       "      <td>0.885545</td>\n",
       "      <td>0.884541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.074700</td>\n",
       "      <td>0.068444</td>\n",
       "      <td>0.975106</td>\n",
       "      <td>0.975158</td>\n",
       "      <td>0.975106</td>\n",
       "      <td>0.975099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.074700</td>\n",
       "      <td>0.561190</td>\n",
       "      <td>0.883572</td>\n",
       "      <td>0.883569</td>\n",
       "      <td>0.883572</td>\n",
       "      <td>0.882453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.093900</td>\n",
       "      <td>0.067714</td>\n",
       "      <td>0.977354</td>\n",
       "      <td>0.977372</td>\n",
       "      <td>0.977354</td>\n",
       "      <td>0.977325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.093900</td>\n",
       "      <td>0.571947</td>\n",
       "      <td>0.876172</td>\n",
       "      <td>0.875109</td>\n",
       "      <td>0.876172</td>\n",
       "      <td>0.874676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>0.066800</td>\n",
       "      <td>0.060030</td>\n",
       "      <td>0.979383</td>\n",
       "      <td>0.979357</td>\n",
       "      <td>0.979383</td>\n",
       "      <td>0.979358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>0.066800</td>\n",
       "      <td>0.559383</td>\n",
       "      <td>0.881598</td>\n",
       "      <td>0.880706</td>\n",
       "      <td>0.881598</td>\n",
       "      <td>0.880698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>0.089100</td>\n",
       "      <td>0.061902</td>\n",
       "      <td>0.978944</td>\n",
       "      <td>0.978946</td>\n",
       "      <td>0.978944</td>\n",
       "      <td>0.978916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>0.089100</td>\n",
       "      <td>0.586890</td>\n",
       "      <td>0.879132</td>\n",
       "      <td>0.877521</td>\n",
       "      <td>0.879132</td>\n",
       "      <td>0.877077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>0.087900</td>\n",
       "      <td>0.063613</td>\n",
       "      <td>0.977792</td>\n",
       "      <td>0.977820</td>\n",
       "      <td>0.977792</td>\n",
       "      <td>0.977729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>0.087900</td>\n",
       "      <td>0.575207</td>\n",
       "      <td>0.883078</td>\n",
       "      <td>0.882682</td>\n",
       "      <td>0.883078</td>\n",
       "      <td>0.881354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>0.071300</td>\n",
       "      <td>0.063915</td>\n",
       "      <td>0.976915</td>\n",
       "      <td>0.976900</td>\n",
       "      <td>0.976915</td>\n",
       "      <td>0.976858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>0.071300</td>\n",
       "      <td>0.584224</td>\n",
       "      <td>0.881598</td>\n",
       "      <td>0.880353</td>\n",
       "      <td>0.881598</td>\n",
       "      <td>0.879738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>0.083300</td>\n",
       "      <td>0.070150</td>\n",
       "      <td>0.975928</td>\n",
       "      <td>0.976027</td>\n",
       "      <td>0.975928</td>\n",
       "      <td>0.975910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>0.083300</td>\n",
       "      <td>0.576318</td>\n",
       "      <td>0.882585</td>\n",
       "      <td>0.881951</td>\n",
       "      <td>0.882585</td>\n",
       "      <td>0.881410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.081300</td>\n",
       "      <td>0.058870</td>\n",
       "      <td>0.980150</td>\n",
       "      <td>0.980143</td>\n",
       "      <td>0.980150</td>\n",
       "      <td>0.980127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.081300</td>\n",
       "      <td>0.558703</td>\n",
       "      <td>0.876172</td>\n",
       "      <td>0.875997</td>\n",
       "      <td>0.876172</td>\n",
       "      <td>0.875325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>0.074600</td>\n",
       "      <td>0.056328</td>\n",
       "      <td>0.981137</td>\n",
       "      <td>0.981168</td>\n",
       "      <td>0.981137</td>\n",
       "      <td>0.981084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>0.074600</td>\n",
       "      <td>0.596644</td>\n",
       "      <td>0.881105</td>\n",
       "      <td>0.880625</td>\n",
       "      <td>0.881105</td>\n",
       "      <td>0.879070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>0.071000</td>\n",
       "      <td>0.061317</td>\n",
       "      <td>0.978560</td>\n",
       "      <td>0.978541</td>\n",
       "      <td>0.978560</td>\n",
       "      <td>0.978531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>0.071000</td>\n",
       "      <td>0.540595</td>\n",
       "      <td>0.882585</td>\n",
       "      <td>0.881850</td>\n",
       "      <td>0.882585</td>\n",
       "      <td>0.880946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>0.079300</td>\n",
       "      <td>0.053181</td>\n",
       "      <td>0.982069</td>\n",
       "      <td>0.982075</td>\n",
       "      <td>0.982069</td>\n",
       "      <td>0.982044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>0.079300</td>\n",
       "      <td>0.580774</td>\n",
       "      <td>0.874198</td>\n",
       "      <td>0.872861</td>\n",
       "      <td>0.874198</td>\n",
       "      <td>0.872135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>0.072000</td>\n",
       "      <td>0.059117</td>\n",
       "      <td>0.979163</td>\n",
       "      <td>0.979190</td>\n",
       "      <td>0.979163</td>\n",
       "      <td>0.979098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>0.072000</td>\n",
       "      <td>0.599252</td>\n",
       "      <td>0.875678</td>\n",
       "      <td>0.873615</td>\n",
       "      <td>0.875678</td>\n",
       "      <td>0.873470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>0.072100</td>\n",
       "      <td>0.054947</td>\n",
       "      <td>0.981576</td>\n",
       "      <td>0.981570</td>\n",
       "      <td>0.981576</td>\n",
       "      <td>0.981542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>0.072100</td>\n",
       "      <td>0.587492</td>\n",
       "      <td>0.881598</td>\n",
       "      <td>0.880135</td>\n",
       "      <td>0.881598</td>\n",
       "      <td>0.879823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>0.065300</td>\n",
       "      <td>0.052728</td>\n",
       "      <td>0.980589</td>\n",
       "      <td>0.980591</td>\n",
       "      <td>0.980589</td>\n",
       "      <td>0.980583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>0.065300</td>\n",
       "      <td>0.564663</td>\n",
       "      <td>0.883572</td>\n",
       "      <td>0.882757</td>\n",
       "      <td>0.883572</td>\n",
       "      <td>0.882078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>0.075700</td>\n",
       "      <td>0.057648</td>\n",
       "      <td>0.980534</td>\n",
       "      <td>0.980541</td>\n",
       "      <td>0.980534</td>\n",
       "      <td>0.980525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>0.075700</td>\n",
       "      <td>0.565597</td>\n",
       "      <td>0.880118</td>\n",
       "      <td>0.879299</td>\n",
       "      <td>0.880118</td>\n",
       "      <td>0.878279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>0.062600</td>\n",
       "      <td>0.053327</td>\n",
       "      <td>0.981357</td>\n",
       "      <td>0.981360</td>\n",
       "      <td>0.981357</td>\n",
       "      <td>0.981338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>0.062600</td>\n",
       "      <td>0.557298</td>\n",
       "      <td>0.882092</td>\n",
       "      <td>0.880635</td>\n",
       "      <td>0.882092</td>\n",
       "      <td>0.880561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.062900</td>\n",
       "      <td>0.050776</td>\n",
       "      <td>0.983331</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.983331</td>\n",
       "      <td>0.983318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.062900</td>\n",
       "      <td>0.540772</td>\n",
       "      <td>0.884558</td>\n",
       "      <td>0.883488</td>\n",
       "      <td>0.884558</td>\n",
       "      <td>0.882851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.082800</td>\n",
       "      <td>0.051543</td>\n",
       "      <td>0.981740</td>\n",
       "      <td>0.981729</td>\n",
       "      <td>0.981740</td>\n",
       "      <td>0.981718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.082800</td>\n",
       "      <td>0.577303</td>\n",
       "      <td>0.887519</td>\n",
       "      <td>0.886945</td>\n",
       "      <td>0.887519</td>\n",
       "      <td>0.885845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81</td>\n",
       "      <td>0.063100</td>\n",
       "      <td>0.051328</td>\n",
       "      <td>0.982453</td>\n",
       "      <td>0.982440</td>\n",
       "      <td>0.982453</td>\n",
       "      <td>0.982422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81</td>\n",
       "      <td>0.063100</td>\n",
       "      <td>0.598979</td>\n",
       "      <td>0.877158</td>\n",
       "      <td>0.876174</td>\n",
       "      <td>0.877158</td>\n",
       "      <td>0.874702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>0.071100</td>\n",
       "      <td>0.044843</td>\n",
       "      <td>0.984208</td>\n",
       "      <td>0.984205</td>\n",
       "      <td>0.984208</td>\n",
       "      <td>0.984185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>0.071100</td>\n",
       "      <td>0.568155</td>\n",
       "      <td>0.886532</td>\n",
       "      <td>0.884483</td>\n",
       "      <td>0.886532</td>\n",
       "      <td>0.884578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>0.056800</td>\n",
       "      <td>0.048405</td>\n",
       "      <td>0.983824</td>\n",
       "      <td>0.983817</td>\n",
       "      <td>0.983824</td>\n",
       "      <td>0.983795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>0.056800</td>\n",
       "      <td>0.587160</td>\n",
       "      <td>0.885545</td>\n",
       "      <td>0.884241</td>\n",
       "      <td>0.885545</td>\n",
       "      <td>0.883570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>0.066900</td>\n",
       "      <td>0.046740</td>\n",
       "      <td>0.983221</td>\n",
       "      <td>0.983225</td>\n",
       "      <td>0.983221</td>\n",
       "      <td>0.983198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>0.066900</td>\n",
       "      <td>0.589425</td>\n",
       "      <td>0.889985</td>\n",
       "      <td>0.888342</td>\n",
       "      <td>0.889985</td>\n",
       "      <td>0.888045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>0.081200</td>\n",
       "      <td>0.050914</td>\n",
       "      <td>0.982508</td>\n",
       "      <td>0.982512</td>\n",
       "      <td>0.982508</td>\n",
       "      <td>0.982473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>0.081200</td>\n",
       "      <td>0.612267</td>\n",
       "      <td>0.888505</td>\n",
       "      <td>0.887223</td>\n",
       "      <td>0.888505</td>\n",
       "      <td>0.886589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>0.064500</td>\n",
       "      <td>0.048362</td>\n",
       "      <td>0.983111</td>\n",
       "      <td>0.983102</td>\n",
       "      <td>0.983111</td>\n",
       "      <td>0.983078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>0.064500</td>\n",
       "      <td>0.566318</td>\n",
       "      <td>0.886532</td>\n",
       "      <td>0.885126</td>\n",
       "      <td>0.886532</td>\n",
       "      <td>0.884779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>0.059300</td>\n",
       "      <td>0.046868</td>\n",
       "      <td>0.983605</td>\n",
       "      <td>0.983608</td>\n",
       "      <td>0.983605</td>\n",
       "      <td>0.983572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>0.059300</td>\n",
       "      <td>0.574413</td>\n",
       "      <td>0.890972</td>\n",
       "      <td>0.889466</td>\n",
       "      <td>0.890972</td>\n",
       "      <td>0.889154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>0.055300</td>\n",
       "      <td>0.047885</td>\n",
       "      <td>0.983056</td>\n",
       "      <td>0.983052</td>\n",
       "      <td>0.983056</td>\n",
       "      <td>0.983036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>0.055300</td>\n",
       "      <td>0.585527</td>\n",
       "      <td>0.886532</td>\n",
       "      <td>0.885098</td>\n",
       "      <td>0.886532</td>\n",
       "      <td>0.884966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89</td>\n",
       "      <td>0.050700</td>\n",
       "      <td>0.045162</td>\n",
       "      <td>0.984921</td>\n",
       "      <td>0.984934</td>\n",
       "      <td>0.984921</td>\n",
       "      <td>0.984910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89</td>\n",
       "      <td>0.050700</td>\n",
       "      <td>0.578910</td>\n",
       "      <td>0.893932</td>\n",
       "      <td>0.892919</td>\n",
       "      <td>0.893932</td>\n",
       "      <td>0.892202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.048900</td>\n",
       "      <td>0.048668</td>\n",
       "      <td>0.982947</td>\n",
       "      <td>0.982933</td>\n",
       "      <td>0.982947</td>\n",
       "      <td>0.982928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.048900</td>\n",
       "      <td>0.571680</td>\n",
       "      <td>0.883572</td>\n",
       "      <td>0.883004</td>\n",
       "      <td>0.883572</td>\n",
       "      <td>0.882045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>0.047100</td>\n",
       "      <td>0.043022</td>\n",
       "      <td>0.984921</td>\n",
       "      <td>0.984910</td>\n",
       "      <td>0.984921</td>\n",
       "      <td>0.984909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>0.047100</td>\n",
       "      <td>0.565156</td>\n",
       "      <td>0.889985</td>\n",
       "      <td>0.889024</td>\n",
       "      <td>0.889985</td>\n",
       "      <td>0.888377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>0.049800</td>\n",
       "      <td>0.045814</td>\n",
       "      <td>0.983550</td>\n",
       "      <td>0.983570</td>\n",
       "      <td>0.983550</td>\n",
       "      <td>0.983516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>0.049800</td>\n",
       "      <td>0.573478</td>\n",
       "      <td>0.886038</td>\n",
       "      <td>0.884887</td>\n",
       "      <td>0.886038</td>\n",
       "      <td>0.884169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93</td>\n",
       "      <td>0.068000</td>\n",
       "      <td>0.044128</td>\n",
       "      <td>0.984756</td>\n",
       "      <td>0.984768</td>\n",
       "      <td>0.984756</td>\n",
       "      <td>0.984751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93</td>\n",
       "      <td>0.068000</td>\n",
       "      <td>0.550624</td>\n",
       "      <td>0.888505</td>\n",
       "      <td>0.887478</td>\n",
       "      <td>0.888505</td>\n",
       "      <td>0.887122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>0.060100</td>\n",
       "      <td>0.042429</td>\n",
       "      <td>0.985195</td>\n",
       "      <td>0.985206</td>\n",
       "      <td>0.985195</td>\n",
       "      <td>0.985181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>0.060100</td>\n",
       "      <td>0.562541</td>\n",
       "      <td>0.883572</td>\n",
       "      <td>0.882507</td>\n",
       "      <td>0.883572</td>\n",
       "      <td>0.882400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>0.038800</td>\n",
       "      <td>0.043649</td>\n",
       "      <td>0.985085</td>\n",
       "      <td>0.985107</td>\n",
       "      <td>0.985085</td>\n",
       "      <td>0.985064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>0.038800</td>\n",
       "      <td>0.561177</td>\n",
       "      <td>0.890479</td>\n",
       "      <td>0.888850</td>\n",
       "      <td>0.890479</td>\n",
       "      <td>0.888626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>0.048500</td>\n",
       "      <td>0.040543</td>\n",
       "      <td>0.986511</td>\n",
       "      <td>0.986509</td>\n",
       "      <td>0.986511</td>\n",
       "      <td>0.986497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>0.048500</td>\n",
       "      <td>0.569111</td>\n",
       "      <td>0.889985</td>\n",
       "      <td>0.888840</td>\n",
       "      <td>0.889985</td>\n",
       "      <td>0.888379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>0.048500</td>\n",
       "      <td>0.044932</td>\n",
       "      <td>0.985140</td>\n",
       "      <td>0.985137</td>\n",
       "      <td>0.985140</td>\n",
       "      <td>0.985115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>0.048500</td>\n",
       "      <td>0.566184</td>\n",
       "      <td>0.888012</td>\n",
       "      <td>0.886656</td>\n",
       "      <td>0.888012</td>\n",
       "      <td>0.886161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>0.053100</td>\n",
       "      <td>0.042853</td>\n",
       "      <td>0.985085</td>\n",
       "      <td>0.985084</td>\n",
       "      <td>0.985085</td>\n",
       "      <td>0.985071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>0.053100</td>\n",
       "      <td>0.570923</td>\n",
       "      <td>0.887025</td>\n",
       "      <td>0.885852</td>\n",
       "      <td>0.887025</td>\n",
       "      <td>0.885440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>0.056500</td>\n",
       "      <td>0.044253</td>\n",
       "      <td>0.984592</td>\n",
       "      <td>0.984592</td>\n",
       "      <td>0.984592</td>\n",
       "      <td>0.984578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>0.056500</td>\n",
       "      <td>0.556057</td>\n",
       "      <td>0.888505</td>\n",
       "      <td>0.887366</td>\n",
       "      <td>0.888505</td>\n",
       "      <td>0.887091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metric = evaluate.load(\"accuracy\")\n",
    "trainer = transformers.Trainer(\n",
    "    # lora_model,\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=val_ds,\n",
    "    tokenizer=image_processor,\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=collate_fn,\n",
    ")\n",
    "\n",
    "trainer.add_callback(CustomCallback(trainer))\n",
    "\n",
    "train_results = trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e9391e-c7c9-4d2a-886f-a5d3072efae4",
   "metadata": {},
   "source": [
    "# Save train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8aa18981-8ff7-43cd-b0a7-a2b9e68e0e40",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** train metrics *****\n",
      "  epoch                    =          99.2\n",
      "  total_flos               = 88031193536GF\n",
      "  train_loss               =        0.2388\n",
      "  train_runtime            =   16:19:51.93\n",
      "  train_samples_per_second =        27.141\n",
      "  train_steps_per_second   =         0.105\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model()\n",
    "trainer.log_metrics(\"train\", train_results.metrics)\n",
    "trainer.save_metrics(\"train\", train_results.metrics)\n",
    "trainer.save_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "16bba3ad-bf5e-44fe-91fe-d449bcd5ba40",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** eval metrics *****\n",
      "  epoch                   =       99.2\n",
      "  eval_accuracy           =      0.916\n",
      "  eval_f1                 =     0.9156\n",
      "  eval_loss               =     0.4329\n",
      "  eval_precision          =     0.9157\n",
      "  eval_recall             =      0.916\n",
      "  eval_runtime            = 0:00:35.19\n",
      "  eval_samples_per_second =     50.399\n",
      "  eval_steps_per_second   =      0.795\n"
     ]
    }
   ],
   "source": [
    "# trainer.evaluate(val_ds)\n",
    "\n",
    "metrics = trainer.evaluate()\n",
    "trainer.log_metrics(\"eval\", metrics)\n",
    "trainer.save_metrics(\"eval\", metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8967e842-822f-4291-810a-6258b7676f2f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://huggingface.co/TriDat/swinv2-base-patch4-window12-192-22k-finetuned-lora-ISIC-2019/tree/main/'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.push_to_hub(\"trantridat/SwinV2Base_lora r64 alpha16 dropout0.05 batchsize64 lr0.001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9d2bb62a-e091-4d10-8de4-4bfbdbe78ff1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer.save_model(\"my_wandb/28042024_Swin/SwinV2Base_lora r64 alpha16 dropout0.05 batchsize64 lr0.001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9f85d172-d8df-44f5-bd1e-283a0aeca2b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lora_model.save_pretrained(\"my_wandb/28042024_Swin/SwinV2Base_lora r64 alpha16 dropout0.05 batchsize64 lr0.001_weight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8b3c83ca-4c61-436f-971a-bc63dd59ca1a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_loss': 0.4329167902469635, 'test_accuracy': 0.9160090191657272, 'test_precision': 0.9156707582414666, 'test_recall': 0.9160090191657272, 'test_f1': 0.9156304372279399, 'test_runtime': 30.8853, 'test_samples_per_second': 57.438, 'test_steps_per_second': 0.907}\n"
     ]
    }
   ],
   "source": [
    "outputs = trainer.predict(val_ds)\n",
    "print(outputs.metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aab8e0c5-b294-4281-8fe5-7c3b1638c961",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading builder script: 100%|██████████| 6.77k/6.77k [00:00<00:00, 15.3MB/s]\n",
      "Downloading builder script: 100%|██████████| 7.55k/7.55k [00:00<00:00, 11.9MB/s]\n",
      "Downloading builder script: 100%|██████████| 7.36k/7.36k [00:00<00:00, 8.47MB/s]\n"
     ]
    }
   ],
   "source": [
    "clf_metrics = evaluate.combine([\"accuracy\", \"f1\", \"precision\", \"recall\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "28b7ba41-beff-4b77-a9bc-10bba3ca2e42",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f3b44096490>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "y_true = outputs.label_ids\n",
    "y_pred = outputs.predictions.argmax(1)\n",
    "\n",
    "labels = val_ds.features['label'].names\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "disp.plot(xticks_rotation=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43fe3ed-f25d-4c00-9102-1956a46616a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d58285-7902-4942-bd57-73b4ae6597a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e5ecf8-37c6-4628-b41b-5e2919b03031",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10561e76-a40b-4ae6-a4cb-10a792db1807",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ed0ae5-c2c7-4c29-b042-0e99f98dbbaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec32f45-c1ba-4bc5-9a63-661d260e105b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d284790b-344a-47e2-ba00-db9a86ba80ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec5c0bd-8b13-45c4-9c7c-7c88a63e67b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9a877d-1272-4919-b59a-9894aa719fbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
